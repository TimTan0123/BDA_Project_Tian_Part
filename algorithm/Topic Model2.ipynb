{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import random\n",
    "import time\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from copy import copy, deepcopy\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from pandas.tseries.offsets import *\n",
    "lmtzr=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_ads = \"/Users/MaxTan/Documents/CU_16fall/BDA/Project/Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_raw = pd.read_csv(data_ads + \"wow3_user2.csv\", names = [\"user_id\", \"review_count\", \"average_stars\", \n",
    "                                               \"friends\", \"fans\", \"votes_cool\", \"votes_funny\", \n",
    "                                               \"votes_useful\", \"num\", \"degree\", \"coefficient\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "business_raw = pd.read_csv(data_ads+\"wow3_business_mysql.csv\", names = [\"business_id\", \"name\", \"latitude\", \n",
    "                                                           \"longitude\", \"stars\", \"categories\", \n",
    "                                                           \"review_count\", \"open\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (3,6,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "review_raw = pd.read_csv(data_ads+\"wow3_review_mysql.csv\", names = [\"review_id\", \"user_id\", \"business_id\", \n",
    "                                                       \"stars\", \"text\", \"date\", \"votes_funny\", \n",
    "                                                       \"votes_useful\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_raw = pd.read_csv(data_ads+\"wow3_all2.csv\", names = [\"business_id\", \n",
    "                                                       \"name\", \"stars_business\",\"business_review_count\",\n",
    "                                                       \"categories\", \"open\", \"review_id\", \n",
    "                                                       \"stars_review\", \"text\", \"date\", \"votes_funny\", \n",
    "                                                       \"votes_useful\",\"user_id\", \"user_review_count\", \n",
    "                                                       \"average_stars\",\"friends\", \"fans\", \"num\", \n",
    "                                                       \"degree\", \"coefficient\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#2.Topic Model by Key Word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbus_gb_df = deepcopy(all_raw)\\n#Group by different businesses for different rates:\\nbus_df = bus_gb_df.groupby([\\'business_id\\']).mean()\\nbus_df[\\'business_id\\'] = bus_df.index\\nbus_df.index = range(len(bus_df))\\nbus = list(set(bus_df[\\'business_id\\']))\\nind = [True if i in bus else False for i in business_raw[\\'business_id\\']]\\nbusiness_revised = business_raw[ind]\\n\\n#Merge two tables:\\nlda_df = pd.merge(bus_df,business_revised,on=\\'business_id\\')\\n\\nstart_time = time.time()\\nbus_topic = dict()\\ncnt = 0\\nfor i in range(len(all_raw)):\\n    ly = all_raw.text[i].lower()\\n    ly = ly.translate(None, string.punctuation)\\n    try:\\n        tokens = nltk.word_tokenize(ly)\\n        tokens = [lmtzr.lemmatize(word) for word in tokens]\\n        tokens = [w for w in tokens if w not in stopwords.words(\"english\")]\\n        #print tokens\\n    except UnicodeDecodeError:\\n        #print tokens\\n        cnt += 1\\n        continue\\n    temp_bus = all_raw.business_id[i]\\n    if temp_bus not in bus_topic:\\n        bus_topic[temp_bus] = tokens\\n    else:\\n        bus_topic[temp_bus] += tokens\\n\\nprint cnt\\n\\nprint(\"--- %s seconds ---\" % (time.time() - start_time))\\n\\nlda_df[\\'tokens\\'] = pd.Series([\\'\\']*len(lda_df),index = lda_df.index)\\nprint len(bus_topic)\\nfor bus in bus_topic:\\n    #print bus\\n    tempdf = lda_df[lda_df[\\'business_id\\']==bus]\\n    temptext = tempdf[\\'categories\\'].values[0].lower()[1:-1]+\\', \\'.join(bus_topic[bus])\\n    lda_df.set_value([tempdf.index[0]],\\'tokens\\',temptext)\\n\\nlda_df.to_csv(\\'business_LDA.csv\\')\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The following codes take 20 minutes to generate a new csv file, which I've store it in the same folder:\n",
    "\"\"\"\n",
    "bus_gb_df = deepcopy(all_raw)\n",
    "#Group by different businesses for different rates:\n",
    "bus_df = bus_gb_df.groupby(['business_id']).mean()\n",
    "bus_df['business_id'] = bus_df.index\n",
    "bus_df.index = range(len(bus_df))\n",
    "bus = list(set(bus_df['business_id']))\n",
    "ind = [True if i in bus else False for i in business_raw['business_id']]\n",
    "business_revised = business_raw[ind]\n",
    "\n",
    "#Merge two tables:\n",
    "lda_df = pd.merge(bus_df,business_revised,on='business_id')\n",
    "\n",
    "start_time = time.time()\n",
    "bus_topic = dict()\n",
    "cnt = 0\n",
    "for i in range(len(all_raw)):\n",
    "    ly = all_raw.text[i].lower()\n",
    "    ly = ly.translate(None, string.punctuation)\n",
    "    try:\n",
    "        tokens = nltk.word_tokenize(ly)\n",
    "        tokens = [lmtzr.lemmatize(word) for word in tokens]\n",
    "        tokens = [w for w in tokens if w not in stopwords.words(\"english\")]\n",
    "        #print tokens\n",
    "    except UnicodeDecodeError:\n",
    "        #print tokens\n",
    "        cnt += 1\n",
    "        continue\n",
    "    temp_bus = all_raw.business_id[i]\n",
    "    if temp_bus not in bus_topic:\n",
    "        bus_topic[temp_bus] = tokens\n",
    "    else:\n",
    "        bus_topic[temp_bus] += tokens\n",
    "\n",
    "print cnt\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "lda_df['tokens'] = pd.Series(['']*len(lda_df),index = lda_df.index)\n",
    "print len(bus_topic)\n",
    "for bus in bus_topic:\n",
    "    #print bus\n",
    "    tempdf = lda_df[lda_df['business_id']==bus]\n",
    "    temptext = tempdf['categories'].values[0].lower()[1:-1]+', '.join(bus_topic[bus])\n",
    "    lda_df.set_value([tempdf.index[0]],'tokens',temptext)\n",
    "\n",
    "lda_df.to_csv('business_LDA.csv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_word = 'pizza'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n",
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel/__main__.py:26: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "\n",
    "\n",
    "\n",
    "lda_df2 = pd.read_csv('business_LDA.csv')\n",
    "ind = [True if search_word in token else False for token in lda_df2.tokens.values]\n",
    "lda_df_sub = lda_df2[ind]\n",
    "\n",
    "lda_df_target = lda_df_sub.sort(['stars_review'],ascending=[0]).iloc[:6]\n",
    "doc_set = list(lda_df_target.tokens.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 11.7504060268 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for i in range(len(doc_set)):\n",
    "    texts = []\n",
    "    #print i\n",
    "    #print 'Name:',lda_df_target.iloc[i:i+1]['name'].values[0]\n",
    "    #print 'Business ID:',lda_df_target.iloc[i:i+1]['business_id'].values[0]\n",
    "    # clean and tokenize document string\n",
    "    raw = doc_set[i].lower()\n",
    "    tokens = tokenizer.tokenize(raw)\n",
    "\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [j for j in tokens if not j in en_stop]\n",
    "    \n",
    "    # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(j) for j in stopped_tokens]\n",
    "    \n",
    "    # add tokens to list\n",
    "    texts.append(stemmed_tokens)\n",
    "\n",
    "    # turn our tokenized documents into a id <-> term dictionary\n",
    "    dictionary = corpora.Dictionary(texts)\n",
    "    \n",
    "    # convert tokenized documents into a document-term matrix\n",
    "    corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "    \n",
    "    ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=10, id2word = dictionary, passes=50)\n",
    "    \n",
    "    result = ldamodel.print_topics(num_topics=10, num_words=10)\n",
    "    \n",
    "    result1 = [j[1] for j in result]\n",
    "    \n",
    "    res_topic = []\n",
    "    \n",
    "    for item in result1:\n",
    "        \n",
    "        res_topic+=str(item).split('\"')[1::2]\n",
    "    \n",
    "    text = \" \".join(res_topic)\n",
    "    \n",
    "    # Generate a word cloud image\n",
    "    wordcloud = WordCloud().generate(text)\n",
    "\n",
    "    # Display the generated image:\n",
    "    # the matplotlib way:\n",
    "\n",
    "    plt.figure(figsize=(100,100),dpi =300)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    #print text\n",
    "    \n",
    "    # take relative word frequencies into account, lower max_font_size\n",
    "    wordcloud = WordCloud(max_font_size=80,stopwords=STOPWORDS,font_path = 'EraserRegular.ttf',\n",
    "                          background_color='blue',max_words=100,width=600,height=600).generate(text)\n",
    "                          #relative_scaling=.8).generate(text)\n",
    "    plt.figure()\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(lda_df_target.iloc[i:i+1]['name'].values[0])\n",
    "    plt.savefig(lda_df_target.iloc[i:i+1]['name'].values[0]+\".jpg\",figsize=(100,100),dpi=100)\n",
    "    plt.close()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
